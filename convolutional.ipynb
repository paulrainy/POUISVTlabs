{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T19:45:27.602856132Z",
     "start_time": "2023-12-22T19:42:07.106658962Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-22 22:42:07.577213: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-22 22:42:07.578738: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-22 22:42:07.602348: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-22 22:42:07.602376: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-22 22:42:07.603305: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-22 22:42:07.607651: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-22 22:42:07.608111: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-22 22:42:08.123290: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 4us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 4s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 1s 0us/step\n",
      "Epoch 1/30 - Loss: 1.1736 - Accuracy: 23.44%\n",
      "Epoch 2/30 - Loss: 1.0641 - Accuracy: 30.42%\n",
      "Epoch 3/30 - Loss: 0.9901 - Accuracy: 31.64%\n",
      "Epoch 4/30 - Loss: 0.8911 - Accuracy: 35.70%\n",
      "Epoch 5/30 - Loss: 0.8354 - Accuracy: 29.62%\n",
      "Epoch 6/30 - Loss: 0.9286 - Accuracy: 39.54%\n",
      "Epoch 7/30 - Loss: 0.9030 - Accuracy: 41.70%\n",
      "Epoch 8/30 - Loss: 0.8922 - Accuracy: 42.60%\n",
      "Epoch 9/30 - Loss: 0.8823 - Accuracy: 43.02%\n",
      "Epoch 10/30 - Loss: 0.8760 - Accuracy: 43.72%\n",
      "Epoch 11/30 - Loss: 0.8693 - Accuracy: 44.06%\n",
      "Epoch 12/30 - Loss: 0.8642 - Accuracy: 44.52%\n",
      "Epoch 13/30 - Loss: 0.8607 - Accuracy: 44.68%\n",
      "Epoch 14/30 - Loss: 0.8585 - Accuracy: 44.88%\n",
      "Epoch 15/30 - Loss: 0.8567 - Accuracy: 44.78%\n",
      "Epoch 16/30 - Loss: 0.8542 - Accuracy: 45.00%\n",
      "Epoch 17/30 - Loss: 0.8520 - Accuracy: 45.24%\n",
      "Epoch 18/30 - Loss: 0.8498 - Accuracy: 45.56%\n",
      "Epoch 19/30 - Loss: 0.8485 - Accuracy: 45.68%\n",
      "Epoch 20/30 - Loss: 0.8474 - Accuracy: 45.78%\n",
      "Epoch 21/30 - Loss: 0.8464 - Accuracy: 45.98%\n",
      "Epoch 22/30 - Loss: 0.8454 - Accuracy: 45.84%\n",
      "Epoch 23/30 - Loss: 0.8446 - Accuracy: 45.98%\n",
      "Epoch 24/30 - Loss: 0.8438 - Accuracy: 46.04%\n",
      "Epoch 25/30 - Loss: 0.8433 - Accuracy: 45.88%\n",
      "Epoch 26/30 - Loss: 0.8428 - Accuracy: 45.86%\n",
      "Epoch 27/30 - Loss: 0.8424 - Accuracy: 45.96%\n",
      "Epoch 28/30 - Loss: 0.8420 - Accuracy: 45.96%\n",
      "Epoch 29/30 - Loss: 0.8417 - Accuracy: 45.98%\n",
      "Epoch 30/30 - Loss: 0.8414 - Accuracy: 46.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.4506"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import correlate2d\n",
    "import tensorflow.keras as keras\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Класс для сверточного слоя\n",
    "class Convolution:\n",
    "\n",
    "    def __init__(self, inputShape, filterSize, numFilters):\n",
    "        inputHeight, inputWidth = inputShape\n",
    "        self.numFilters = numFilters\n",
    "        self.inputShape = inputShape\n",
    "\n",
    "        # Размеры выходных данных и фильтров\n",
    "        self.filterShape = (numFilters, filterSize, filterSize)\n",
    "        self.outputShape = (numFilters, inputHeight - filterSize + 1, inputWidth - filterSize + 1)\n",
    "\n",
    "        self.filters = np.random.randn(*self.filterShape)\n",
    "        self.biases = np.random.randn(*self.outputShape)\n",
    "\n",
    "    # Прямой проход\n",
    "    def forward(self, inputData):\n",
    "        self.inputData = inputData\n",
    "        output = np.zeros(self.outputShape)\n",
    "        for i in range(self.numFilters):\n",
    "            output[i] = correlate2d(self.inputData, self.filters[i], mode=\"valid\")\n",
    "        output = np.maximum(output, 0)\n",
    "        return output\n",
    "\n",
    "    # Обратный проход\n",
    "    def backward(self, dL_dout, lr):\n",
    "        dL_dinput = np.zeros_like(self.inputData)\n",
    "        dL_dfilters = np.zeros_like(self.filters)\n",
    "\n",
    "        for i in range(self.numFilters):\n",
    "            dL_dfilters[i] = correlate2d(self.inputData, dL_dout[i],mode=\"valid\")\n",
    "            dL_dinput += correlate2d(dL_dout[i],self.filters[i], mode=\"full\")\n",
    "\n",
    "        self.filters -= lr * dL_dfilters\n",
    "        self.biases -= lr * dL_dout\n",
    "\n",
    "        return dL_dinput\n",
    "\n",
    "# Класс для слоя максимального пулинга\n",
    "class MaxPool:\n",
    "\n",
    "    def __init__(self, poolSize):\n",
    "        self.poolSize = poolSize\n",
    "\n",
    "    # Прямой проход\n",
    "    def forward(self, inputData):\n",
    "        self.inputData = inputData\n",
    "        self.numChannels, self.inputHeight, self.inputWidth = inputData.shape\n",
    "        self.outputHeight = self.inputHeight // self.poolSize\n",
    "        self.outputWidth = self.inputWidth // self.poolSize\n",
    "\n",
    "        self.output = np.zeros((self.numChannels, self.outputHeight, self.outputWidth))\n",
    "\n",
    "        for c in range(self.numChannels):\n",
    "            for i in range(self.outputHeight):\n",
    "                for j in range(self.outputWidth):\n",
    "                    startI = i * self.poolSize\n",
    "                    startJ = j * self.poolSize\n",
    "                    endI = startI + self.poolSize\n",
    "                    endJ = startJ + self.poolSize\n",
    "                    patch = inputData[c, startI:endI, startJ:endJ]\n",
    "                    self.output[c, i, j] = np.max(patch)\n",
    "\n",
    "        return self.output\n",
    "\n",
    "    # Обратный проход\n",
    "    def backward(self, dL_dout, lr):\n",
    "        dL_dinput = np.zeros_like(self.inputData)\n",
    "\n",
    "        for c in range(self.numChannels):\n",
    "            for i in range(self.outputHeight):\n",
    "                for j in range(self.outputWidth):\n",
    "                    startI = i * self.poolSize\n",
    "                    startJ = j * self.poolSize\n",
    "                    endI = startI + self.poolSize\n",
    "                    endJ = startJ + self.poolSize\n",
    "                    patch = self.inputData[c, startI:endI, startJ:endJ]\n",
    "                    mask = patch == np.max(patch)\n",
    "                    dL_dinput[c,startI:endI, startJ:endJ] = dL_dout[c, i, j] * mask\n",
    "\n",
    "        return dL_dinput\n",
    "\n",
    "# Класс для полносвязного слоя\n",
    "class FullyConnected:\n",
    "\n",
    "    def __init__(self, inputSize, outputSize):\n",
    "        self.inputSize = inputSize\n",
    "        self.outputSize = outputSize\n",
    "        self.weights = np.random.randn(outputSize, self.inputSize)\n",
    "        self.biases = np.random.rand(outputSize, 1)\n",
    "\n",
    "    # Функция активации softmax\n",
    "    def softmax(self, z):\n",
    "        shiftedZ = z - np.max(z)\n",
    "        expValues = np.exp(shiftedZ)\n",
    "        sumExpValues = np.sum(expValues, axis=0)\n",
    "        probabilities = expValues / sumExpValues\n",
    "        return probabilities\n",
    "\n",
    "    # Производная softmax\n",
    "    def softmaxDerivative(self, s):\n",
    "        return np.diagflat(s) - np.dot(s, s.T)\n",
    "\n",
    "    # Прямой проход\n",
    "    def forward(self, inputData):\n",
    "        self.inputData = inputData\n",
    "        flattenedInput = inputData.flatten().reshape(1, -1)\n",
    "        self.z = np.dot(self.weights, flattenedInput.T) + self.biases\n",
    "        self.output = self.softmax(self.z)\n",
    "        return self.output\n",
    "\n",
    "    # Обратный проход\n",
    "    def backward(self, dL_dout, lr):\n",
    "        dL_dy = np.dot(self.softmaxDerivative(self.output), dL_dout)\n",
    "        dL_dw = np.dot(dL_dy, self.inputData.flatten().reshape(1, -1))\n",
    "        dL_db = dL_dy\n",
    "        dL_dinput = np.dot(self.weights.T, dL_dy)\n",
    "        dL_dinput = dL_dinput.reshape(self.inputData.shape)\n",
    "        self.weights -= lr * dL_dw\n",
    "        self.biases -= lr * dL_db\n",
    "        return dL_dinput\n",
    "\n",
    "# Функция потерь - кросс-энтропия\n",
    "def crossEntropyLoss(predictions, targets):\n",
    "    numSamples = 10\n",
    "    epsilon = 1e-7\n",
    "    predictions = np.clip(predictions, epsilon, 1 - epsilon)\n",
    "    loss = -np.sum(targets * np.log(predictions)) / numSamples\n",
    "    return loss\n",
    "\n",
    "# Градиент функции потерь\n",
    "def crossEntropyLossGradient(actualLabels, predictedProbs):\n",
    "    numSamples = actualLabels.shape[0]\n",
    "    gradient = -actualLabels / (predictedProbs + 1e-7) / numSamples\n",
    "    return gradient\n",
    "\n",
    "# Обучение сети\n",
    "def trainNetwork(X, y, conv, pool, full, lr=0.01, epochs=30):\n",
    "    for epoch in range(epochs):\n",
    "        totalLoss = 0.0\n",
    "        correctPredictions = 0\n",
    "\n",
    "        for i in range(len(X)):\n",
    "            convOut = conv.forward(X[i])\n",
    "            poolOut = pool.forward(convOut)\n",
    "            fullOut = full.forward(poolOut)\n",
    "            loss = crossEntropyLoss(fullOut.flatten(), y[i])\n",
    "            totalLoss += loss\n",
    "\n",
    "            oneHotPred = np.zeros_like(fullOut)\n",
    "            oneHotPred[np.argmax(fullOut)] = 1\n",
    "            oneHotPred = oneHotPred.flatten()\n",
    "\n",
    "            numPred = np.argmax(oneHotPred)\n",
    "            numY = np.argmax(y[i])\n",
    "\n",
    "            if numPred == numY:\n",
    "                correctPredictions += 1\n",
    "\n",
    "            gradient = crossEntropyLossGradient(y[i], fullOut.flatten()).reshape((-1, 1))\n",
    "            fullBack = full.backward(gradient, lr)\n",
    "            poolBack = pool.backward(fullBack, lr)\n",
    "            convBack = conv.backward(poolBack, lr)\n",
    "\n",
    "        averageLoss = totalLoss / len(X)\n",
    "        accuracy = correctPredictions / len(X_train) * 100.0\n",
    "        print(f\"Epoch {epoch + 1}/{epochs} - Loss: {averageLoss:.4f} - Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Предсказание\n",
    "def predict(inputSample, conv, pool, full):\n",
    "    convOut = conv.forward(inputSample)\n",
    "    poolOut = pool.forward(convOut)\n",
    "    flattenedOutput = poolOut.flatten()\n",
    "    predictions = full.forward(flattenedOutput)\n",
    "    return predictions\n",
    "\n",
    "# Загрузка данных\n",
    "(trainImages, trainLabels), (testImages, testLabels) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train = trainImages[:5000] / 255.0\n",
    "y_train = trainLabels[:5000]\n",
    "\n",
    "X_test = trainImages[5000:10000] / 255.0\n",
    "y_test = trainLabels[5000:10000]\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "conv = Convolution(X_train[0].shape, 6, 1)\n",
    "pool = MaxPool(2)\n",
    "full = FullyConnected(121, 10)\n",
    "\n",
    "trainNetwork(X_train, y_train, conv, pool, full)\n",
    "\n",
    "predictions = []\n",
    "for data in X_test:\n",
    "    pred = predict(data, conv, pool, full)\n",
    "    oneHotPred = np.zeros_like(pred)\n",
    "    oneHotPred[np.argmax(pred)] = 1\n",
    "    predictions.append(oneHotPred.flatten())\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "\n",
    "accuracy_score(predictions, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
